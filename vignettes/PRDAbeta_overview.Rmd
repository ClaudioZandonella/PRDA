---
title: "PRDAbeta: Prospective and Retrospective Design Analysis"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{PRDAbeta_overview}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: PRDA.bib
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


Given a plausible value of effect size, {PRDAbeta} performs a prospective or retrospective design analysis to evaluate the inferential risks (i.e., power, Type M error, and Type S error) related to the study design.

### Some background information

The term *Design Analysis* was introduced by @gelmanPowerCalculationsAssessing2014 as a broader definition of Power Analysis. Traditional power analysis has a narrow focus on statistical significance. Design analysis, instead, evaluates together with power levels also other inferential risks (i.e., Type M error and Type S error), to assess estimates uncertainty under hypothetical replications of a study.

Given a *plausible effect size* and study characteristics (i.e., sample size, statistical test directionality, $\alpha$ level), design analysis evaluates:

- **Power**: the probability of the test rejecting the null hypothesis.
- **Type M error** (Magnitude): the factor by which a statistically significant effect is on average exaggerated, also known as *Exaggeration Ratio*.
- **Type S error** (Sign): the probability of finding a statistically significant result in the opposite direction to the plausible one.

Although Type M error and Type S error depends directly on power level, they allow enhancing researchers awareness about the inferential risks related to their studies. For example, obtaining a  significant result in a study with 40% of power could sound a promising finding to the researchers. However, knowing that this is associated with a Type M error of almost 1.60 (i.e., on average significant results are an overestimation of 60%) would warn researchers to interpret their results with caution.

Moreover, @gelmanPowerCalculationsAssessing2014 distinguished between two types of design analysis according to the study phase:

- **Prospective Design Analysis**: if the analysis is performed in the planning stage of the study to define the sample size needed to obtain a required level of power.
- **Retrospective Design Analysis**: if the analysis is performed in a later stage when the data have already been collected. This is still useful to evaluate the inferential risks associated with the study.

It is important to do not mistake a retrospective design analysis for post-hoc power analysis. The former defines the plausible effect size according to previous results in the literature or experts' indications, whereas the latter defines the plausible effect size based on the same study results and it is a widely-deprecated practice [@goodmanUsePredictedConfidence1994; @lenthStatisticalPowerCalculations12007; @Senn1304].

To know more about design analysis consider @gelmanPowerCalculationsAssessing2014. While, for an introduction about design analysis considering examples in psychology see @altoeEnhancingStatisticalInference2020 and  @bertoldoDesigningStudiesEvaluating2020.

### The package

PRDAbeta package can be used for Pearson's correlation between two variables or mean comparisons (i.e., one-sample, paired, two-samples, and Welch's t-test) considering a plausible value of $\rho$ or Cohen's *d* respectively. See [`vignette("retrospective")`](retrospective.html) to know how to set function arguments for the different effect types. 

#### Install

To install the github version type in R:

```{r setup, eval = F}
# If devtools is not installed yet: 
# install.packages( "devtools" )  
devtools::install_github("CaludioZandonella/PRDAbeta",
                         build_vignettes = TRUE)
library(PRDAbeta)
```

#### Functions

In {PRDAbeta} there are two main functions:

- **`retrospective()`**.
Given the hypothetical population effect size and the study sample size, the function `retrospective()` performs a retrospective design analysis for Pearson's correlation test between two variables or Cohen's *d* (t-test comparing group means). According to the defined alternative hypothesis and the significance level, the inferential risks (i.e., Power level, Type M error, and Type S error) are computed together with the critical effect value (i.e., the minimum absolute effect size value that would result significant). To know more about function arguments and examples see the function documentation `?retrospective()` and  [`vignette("retrospective")`](retrospective.html).

- **`prospective()`**.
Given the hypothetical population effect size and the required power level, the function `prospective()` performs a prospective design analysis for Pearson's correlation test between two variables or Cohen's *d* (t-test comparing group means). According to the defined alternative hypothesis and the significance level, the required sample size is computed together with the associated Type M error, Type S error, and the critical correlation value (i.e., the minimum absolute effect size value that would result significant).  To know more about function arguments and examples see the function documentation `?prospective()` and [`vignette("prospective")`](prospective.html).

#### Hypothetical effect size

The hypothetical population effect size can be defined as a single value or as a distribution of plausible values. This is a useful feature of {PRDAbeta}, as it allows users to define hypothetical effect size according to a distribution representing their expectations or literature indications. For an example of application see [`vignette("retrospective")`](retrospective.html).

### References



